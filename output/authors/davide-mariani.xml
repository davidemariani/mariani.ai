<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Davide Mariani's personal blog (Posts by Davide Mariani)</title><link>https://mariani.ai/</link><description></description><atom:link href="https://mariani.ai/authors/davide-mariani.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2022 &lt;a href="mailto:davide@mariani.ai"&gt;Davide Mariani&lt;/a&gt; </copyright><lastBuildDate>Mon, 03 Jan 2022 16:34:26 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>A quick introduction to Graph Neural Networks</title><link>https://mariani.ai/posts/a-quick-introduction-to-graph-neural-networks/</link><dc:creator>Davide Mariani</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;em&gt;Geometric Deep Learning&lt;/em&gt; &lt;a href="https://twitter.com/prlz77/status/1178662575900368903"&gt;has become increasingly popular over the past few years&lt;/a&gt;, and I have recently become more and more interested in them.&lt;br&gt;
In this post, I will try to compress the main intuitions (at a very high level) behind &lt;em&gt;Graph neural networks&lt;/em&gt;, so that it will be easier to get to more detailed aspects in the future posts.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://mariani.ai/posts/a-quick-introduction-to-graph-neural-networks/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>https://mariani.ai/posts/a-quick-introduction-to-graph-neural-networks/</guid><pubDate>Mon, 03 Jan 2022 16:20:29 GMT</pubDate></item></channel></rss>